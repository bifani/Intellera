{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9489e9d",
   "metadata": {},
   "source": [
    "# Importings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab72808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import folium\n",
    "import geopandas as gpd\n",
    "import branca.colormap as cm\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bb5c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.model_selection import cross_val_predict, cross_validate, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    "    roc_curve,\n",
    "    roc_auc_score,\n",
    "    auc,\n",
    "    precision_recall_fscore_support,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4786e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from xgboost import XGBClassifier\n",
    "import shap\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pip install lime\n",
    "# import lime\n",
    "# from lime import lime_tabular\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# from statsmodels.tools.tools import add_constant\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#  pip install xgboost\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b656f322",
   "metadata": {},
   "source": [
    "# Loading Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108fab01",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom = pd.read_csv(\"NDOM_FINAL.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa231f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom.groupby(\"NUM_CIR\")[[\"IMPORTO_CONTRATTO\", \"IMPORTO_PAREGGIO\"]].agg(\n",
    "    [\"count\", \"sum\", \"median\", \"mean\", \"min\", \"max\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6829ba",
   "metadata": {},
   "source": [
    "### Build a new feature to transform the problem into a classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5657080",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom[\"par/em\"] = dfdom[\"IMPORTO_PAREGGIO\"] / dfdom[\"IMPORTO_CONTRATTO\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9fd3256",
   "metadata": {},
   "source": [
    "### Drop unrelevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18433d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90765145",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom = dfdom.drop(\n",
    "    columns=[\n",
    "        \"Unnamed: 0\",\n",
    "        \"CNT_COD\",\n",
    "        \"CONTO\",\n",
    "        \"NUM_FATT\",\n",
    "        \"UTZ_CONTRATTO\",\n",
    "        \"DATA_EMISSIONE\",\n",
    "        \"IMPORTO_CONTRATTO\",\n",
    "        \"MOTIVO_PAREGGIO\",\n",
    "        \"DATA_PAREGGIO\",\n",
    "        \"IMPORTO_PAREGGIO\",\n",
    "        \"TIPO_DOC_PAREGGIO\",\n",
    "        \"CNT_COGNOME\",\n",
    "        \"CNT_NOME\",\n",
    "        \"CNT_RAG_SOC\",\n",
    "        \"CNT_PAR_IVA\",\n",
    "        \"CNT_COD_FSC\",\n",
    "        \"UTZ_TARIFTYP\",\n",
    "        \"UTZ_VIA_DES\",\n",
    "        \"UTZ_NUM_CIV\",\n",
    "        \"CAP\",\n",
    "        \"COD_ZON_URB\",\n",
    "        \"FLAG_DECEDUTO\",\n",
    "        \"FLAG_CESSATA\",\n",
    "        \"RI_CLEAN_STA_PAR_IVA\",\n",
    "        \"FLAG_PEC_SAP\",\n",
    "        \"SEMESTRE\",\n",
    "        \"FLAG_PEC_INV\",\n",
    "        \"FLAG_NOPEC\",\n",
    "        \"FLAG_PEC\",\n",
    "        \"FLAG_ESENTE_SAP\",\n",
    "        \"FLAG_ESENTE_RIC\",\n",
    "        \"FLAG_ESENTE\",\n",
    "        \"FLAG_RATE_SAP\",\n",
    "        \"NUM_RATE\",\n",
    "        \"IMPORTO_RATEIZZATO\",\n",
    "        \"FLAG_RATE_RIC\",\n",
    "        \"FLAG_RATE\",\n",
    "        \"FLAG_BOLLETTINO\",\n",
    "        \"FLAG_DATI_ERRATI\",\n",
    "        \"IMPORTO_CONTRATTO_NO_TEFA\",\n",
    "        \"IMPORTO_PAREGGIO_NO_TEFA\",\n",
    "        \"FLAG_NON_RECAPITATO\",\n",
    "        \"PERCENTUALE_NON_PAGATO\",\n",
    "        \"FLAG_PAGATO\",\n",
    "        \"FLAG_COPIA_CONFORME\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375c049",
   "metadata": {},
   "source": [
    "### we have 260455:0  941030:1 8:nan, 529 values that have partially paid amounts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5575d8bc",
   "metadata": {},
   "source": [
    "### We consider not a numbers as paid, because are divisions by zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95795aa7",
   "metadata": {},
   "source": [
    "# Construct the class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3cccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dfdom[\"par/em\"]  # class label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e345176",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(target)  # the ones are the paid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b2fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target.replace(np.nan, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287d9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(target)):\n",
    "    if (target[i] != 1.0) and (target[i] != 0.0):\n",
    "        target[i] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59296444",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380982e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom[\"target\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c91881",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom = dfdom.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdfc2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom = dfdom.drop(columns=\"par/em\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b91a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.unique(dfdom[\"SUPERFICIE\"], return_counts=True)[0])  # abbiamo 908 valori differenti della superficie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d788b",
   "metadata": {},
   "source": [
    "### putting them in different bins to create a categorical feature (library:qcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3249df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfdom.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab5930c",
   "metadata": {},
   "source": [
    "### One hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the dx for the following correlation\n",
    "ohe = OneHotEncoder(\n",
    "    sparse=False, drop=\"if_binary\", categories=\"auto\"\n",
    ")  # dummy variable trap - evitata con drop='if_binary'\n",
    "\n",
    "CNT_TCN_COD = pd.DataFrame(ohe.fit_transform(dfdom[\"CNT_TCN_COD\"].values.reshape(-1, 1)))\n",
    "SUPERFICIE = pd.DataFrame(\n",
    "    ohe.fit_transform(dfdom[\"SUPERFICIE\"].values.reshape(-1, 1))\n",
    ")  # range(istogramma , b8in) quantili\n",
    "# qcat pandas taglia in quantili\n",
    "# COMPONENTI=pd.DataFrame(ohe.fit_transform(dfdom['COMPONENTI'].values.reshape(-1, 1)))\n",
    "NUM_CIR = pd.DataFrame(ohe.fit_transform(dfdom[\"NUM_CIR\"].values.reshape(-1, 1)))\n",
    "target = pd.DataFrame(ohe.fit_transform(dfdom[\"target\"].values.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a8c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CIR.columns=['CIR0',  'CIR1',  'CIR2',  'CIR3',  'CIR4',  'CIR5',  'CIR6',  'CIR7',\n",
    "#                      'CIR8',  'CIR9', 'CIR10', 'CIR11', 'CIR12','CIR13', 'CIR14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd0795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_CIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a77576",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a316b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73feff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CNT_TCN_COD\"] = CNT_TCN_COD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c5e53c",
   "metadata": {},
   "source": [
    "# Ordering \"Municipi\" by number of \"utenze\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eafa68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfd=pd.read_csv('NDOM_FINAL.csv')\n",
    "# ord_cir=dfd.groupby('NUM_CIR')[['IMPORTO_CONTRATTO']].agg(\n",
    "#     ['count']\n",
    "# )\n",
    "# ord_cir=ord_cir['IMPORTO_CONTRATTO'].sort_values(by='count',ascending=True).index.values\n",
    "# ord_cir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af3bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"NUM_CIR\"].replace(\n",
    "    {\n",
    "        15.0: 1.0,\n",
    "        14.0: 2.0,\n",
    "        13.0: 3.0,\n",
    "        11.0: 4.0,\n",
    "        8.0: 5.0,\n",
    "        6.0: 6.0,\n",
    "        4.0: 7.0,\n",
    "        9.0: 8.0,\n",
    "        12.0: 9.0,\n",
    "        3.0: 10.0,\n",
    "        10.0: 11.0,\n",
    "        5.0: 12.0,\n",
    "        2.0: 13.0,\n",
    "        7.0: 14.0,\n",
    "        1.0: 15.0,\n",
    "    },\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402f438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns=[ 'CNT_TCN_COD',  'SUP0',  'SUP1',  'SUP2',  'SUP3',  'COMP0',  'COMP1',  'COMP2',  'COMP3',  'COMP4',\n",
    "#                     'COMP5',  'COMP6',  'COMP7',  'COMP8',  'COMP9', 'COMP10', 'COMP11',\n",
    "#                     'COMP12', 'COMP13', 'COMP14', 'COMP15',  'CIR0',  'CIR1',  'CIR2',  'CIR3',  'CIR4',  'CIR5',  'CIR6',  'CIR7',\n",
    "#                     'CIR8',  'CIR9', 'CIR10', 'CIR11', 'CIR12','CIR13', 'CIR14',  'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b5547c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da483ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefb74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = features[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7580d1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.drop(columns=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e4ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16914cbe",
   "metadata": {},
   "source": [
    "# Train test split (stratified)\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90f894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.12, random_state=999, stratify=target)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=999, stratify=y_train)\n",
    "print(\"Shape of entire dataset: {}\".format(str(features.shape)))\n",
    "print(\"Shape of train data: {}\".format(str(X_train.shape)))\n",
    "print(\"Shape of test data: {}\".format(str(X_test.shape)))\n",
    "print(\"Shape of val data: {}\".format(str(X_val.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588187d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"CNT_TCN_COD\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93ca01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CNT_TCN_COD\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967b6661",
   "metadata": {},
   "source": [
    "# Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e79deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "# rus.fit(X_train, y_train)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94a6c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d9437",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c874222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11818f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4971eaca",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_train) - np.sum(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885b28f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eba684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb50a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819ba8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr[\"tar\"] = y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ebd4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c22df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = X_tr[\"tar\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e09cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_tr.drop(columns=\"tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9685814",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9176c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbe96f8",
   "metadata": {},
   "source": [
    "# Feature Importance  SHAP- XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5687a619",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "score = model.score(X_val, y_val)  # e poi validation è anche più grande del test\n",
    "shap.initjs()\n",
    "explainer = shap.TreeExplainer(model)\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "shap.summary_plot(shap_values, X_train, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1a595a",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"violin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, plot_type=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff70c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshap = pd.DataFrame(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89429838",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e63d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfshap.columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfdb6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfshap.columns)):\n",
    "    print(dfshap.columns[i], \": \", np.sum(dfshap[dfshap.columns[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3778b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = explainer.shap_interaction_values(X_train)  # ha solo il dot\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028d831",
   "metadata": {},
   "source": [
    "Synergy= the interaction or cooperation of two or more organizations, substances, or other agents to produce a combined effect greater than the sum of their separate effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5317738",
   "metadata": {
    "id": "FufnhVm7_xkV"
   },
   "source": [
    "### Analyze it using ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc75b3b",
   "metadata": {
    "id": "PhZSxP-Ggu0u"
   },
   "source": [
    "Using a decison tree with criteria based on Gini impurity for the information gain in order to find the feature's relevance. Where S is the set of items and Si is the the set of items of the i-esim class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ca2a59",
   "metadata": {
    "id": "HgJTeZFqqF1R"
   },
   "source": [
    "Gini index of S $$  GS = 1 - \\sum_{i=1}^k ({\\frac{\\vert S_i \\vert }{\\vert S \\vert}}) ^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21a92b",
   "metadata": {
    "id": "Ba2NfYzaDLxO"
   },
   "source": [
    "Extremely Randomized Trees Classifier.\n",
    "This is an ensemble learning technique that output it's classification result aggregating the results of a \"forest\" of multiple uncorrelated decision trees.\n",
    "Each tree, at each test node, is provided with a k random sample of features from the feature set.\n",
    "Each decision tree must select the best feature to split the data based on a mathematical criteria, in our case the Gini Impurity.\n",
    "This random sample of features leads to the creation of multiple uncorrelated decision trees.\n",
    "The normalized total reduction in the Gini Impurity, i.e. the Gini Importance of the feature, is computed during the construction of the forest for each feature.\n",
    "Each feature is ordered according to the Gini Importance of each feature and this allows us to perform the feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528955e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 486
    },
    "id": "yQOswuqbMCDX",
    "outputId": "87a0ab93-2679-406c-aa04-ca36bdf810db"
   },
   "outputs": [],
   "source": [
    "X = X_train  # .drop(labels=['age','dx','label_dx','dx_vec','color_vector'],axis=1)\n",
    "y = y_train\n",
    "# sc = StandardScaler()\n",
    "# sc = sc.fit(X)\n",
    "# X_s = pd.DataFrame(sc.transform(X), columns=X.columns)\n",
    "forest = ExtraTreesClassifier(criterion=\"gini\", n_estimators=250, random_state=0)\n",
    "X_s = X\n",
    "# proviamo a vedere intanto cosa esce fuori tenendo solo le features numeriche\n",
    "# X_s = X_s.apply(pd.to_numeric)#, errors='coerce')\n",
    "# X_s['MOTIVO_PAREGGIO']=X_s['MOTIVO_PAREGGIO'].replace(np.nan,0.)\n",
    "# X_s['NUM_RATE']=X_s['NUM_RATE'].replace(np.nan,0.)\n",
    "# X_s['IMPORTO_RATEIZZATO']=X_s['IMPORTO_RATEIZZATO'].replace(np.nan,0.)\n",
    "# X_s=X_s.dropna().reset_index(drop=True)#ho controllato, restano nan solo sulle circoscrizioni mancanti\n",
    "# il problema è che poi non ho modificato di conseguenza anche y\n",
    "forest.fit(X_s, y)\n",
    "importances = forest.feature_importances_\n",
    "ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "dd = pd.DataFrame(ff, columns=X.columns)\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(data=dd, ci=\"sd\", alpha=0.7)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature relevance for classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3920bf91",
   "metadata": {},
   "source": [
    "## See how the model reacts changing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef57b219",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier(criterion=\"entropy\", n_estimators=250, random_state=0)\n",
    "X_s = X\n",
    "forest.fit(X_s, y)\n",
    "importances = forest.feature_importances_\n",
    "ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "dd = pd.DataFrame(ff, columns=X.columns)\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(data=dd, ci=\"sd\", alpha=0.7)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature relevance for classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23bbe5ae",
   "metadata": {},
   "source": [
    "### log_loss does not work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0967266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ExtraTreesClassifier(criterion=\"gini\", n_estimators=50, random_state=0)\n",
    "X_s = X\n",
    "forest.fit(X_s, y)\n",
    "importances = forest.feature_importances_\n",
    "ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "dd = pd.DataFrame(ff, columns=X.columns)\n",
    "fig = plt.figure(figsize=(16, 6))\n",
    "sns.barplot(data=dd, ci=\"sd\", alpha=0.7)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Feature relevance for classification\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbea05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest = ExtraTreesClassifier(criterion = 'gini', n_estimators=500, random_state=0)\n",
    "# X_s=X\n",
    "# forest.fit(X_s, y)\n",
    "# importances = forest.feature_importances_\n",
    "# ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "# dd = pd.DataFrame(ff, columns=X.columns)\n",
    "# fig = plt.figure(figsize=(16, 6))\n",
    "# sns.barplot(data=dd, ci=\"sd\", alpha=.7)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Feature relevance for classification')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a809d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest = ExtraTreesClassifier(criterion = 'gini', n_estimators=10, random_state=0)\n",
    "# X_s=X\n",
    "# forest.fit(X_s, y)\n",
    "# importances = forest.feature_importances_\n",
    "# ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "# dd = pd.DataFrame(ff, columns=X.columns)\n",
    "# fig = plt.figure(figsize=(16, 6))\n",
    "# sns.barplot(data=dd, ci=\"sd\", alpha=.7)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Feature relevance for classification')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc606988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forest = ExtraTreesClassifier(criterion = 'entropy', n_estimators=10, random_state=0)\n",
    "# X_s=X\n",
    "# forest.fit(X_s, y)\n",
    "# importances = forest.feature_importances_\n",
    "# ff = np.array([e.feature_importances_ for e in forest.estimators_])\n",
    "# dd = pd.DataFrame(ff, columns=X.columns)\n",
    "# fig = plt.figure(figsize=(16, 6))\n",
    "# sns.barplot(data=dd, ci=\"sd\", alpha=.7)\n",
    "# plt.xticks(rotation=90)\n",
    "# plt.title('Feature relevance for classification')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6fc0509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_t=X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202061ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_t['target']=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df390f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explainer = lime_tabular.LimeTabularExplainer(\n",
    "#     training_data=np.array(X_train),\n",
    "#     feature_names=X_train.columns,\n",
    "#     class_names=['target'],\n",
    "#     mode='classification'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d886ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define dataset\n",
    "# # X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# # define the model\n",
    "# model = LogisticRegression()\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# score = model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bd2f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train=X_train.drop(columns='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6838f652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp = explainer.explain_instance(\n",
    "#     data_row=X_train.iloc[1],\n",
    "#     predict_fn=model.predict_proba\n",
    "# )\n",
    "\n",
    "# exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb7d646",
   "metadata": {},
   "source": [
    "\n",
    "## Tree models are not working well with OHE!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9acc51",
   "metadata": {},
   "source": [
    "Tree-based models, such as Decision Trees, Random Forests, and Boosted Trees, typically don't perform well with one-hot encodings with lots of levels. This is because they pick the feature to split on based on how well that splitting the data on that feature will \"purify\" it. If we have a lot of levels, only a small fraction of the data (typically) will belong to any given level, so the one-hot encoded columns will be mostly zeros. Since splitting on this column will only produce a small gain, tree-based algorithms typically ignore the information in favor of other columns. This problem persists, regardless of the volume of data you actually have."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd60291e",
   "metadata": {},
   "source": [
    "###  Mutual Info Classification to measure the dependency between the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d2dab0",
   "metadata": {},
   "source": [
    "Mutual Info Classification in order to measure the dependency between the variables. It is equal to zero if and only if two random variables are independent, and higher values mean higher dependency. The function relies on nonparametric methods based on entropy estimation:\n",
    "\\begin{equation}\n",
    "    Entropy(x) = - \\sum_{x} {p(x) log_2 p(x)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e438ff64",
   "metadata": {},
   "source": [
    "# Logistic Regression  Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606507c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.coef_[0]\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print(\"Feature: %s, Score: %.5f\" % (X_train.columns[i], v))\n",
    "# plot feature importance\n",
    "plt.bar([x for x in range(len(importance))], importance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7545bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(X_train.columns).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780f4d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame()\n",
    "df_imp[\"features\"] = X_train.columns\n",
    "df_imp[\"importance\"] = np.abs(importance)\n",
    "df_imp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "variance = np.diagonal(np.linalg.inv(np.dot(X_train.T, X_train)) * model.coef_.T.dot(model.coef_))\n",
    "print(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d9639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame()\n",
    "df_imp[\"features\"] = X_train.columns\n",
    "df_imp[\"importance\"] = np.abs(importance)\n",
    "df_imp[\"variance\"] = variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cbb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xs = add_constant(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74da5657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657d7b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression().fit(Xs, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6114d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vif = pd.DataFrame()\n",
    "# vif[\"VIF Factor\"] = [variance_inflation_factor(Xs.values, i) for i in range(Xs.shape[1])]\n",
    "# vif[\"features\"] = Xs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fd9d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(vif)\n",
    "#  VIF > 5 indicate high multicollinearity, which means they are\n",
    "# highly correlated with each other and may be contributing to the\n",
    "# variance in the model. You can drop these features or try to address\n",
    "# the multicollinearity by combining them into a single feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f62b87c",
   "metadata": {},
   "source": [
    "## Using statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d80aa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the logistic regression model\n",
    "model = sm.Logit(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary output\n",
    "print(model.summary())  # i coefficienti sono gli stessi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38930546",
   "metadata": {},
   "source": [
    "# Probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Probit(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary output\n",
    "print(model.summary())  # i coefficienti sono gli stessi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f5819c",
   "metadata": {},
   "source": [
    "# CART Feature Importance(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb19e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decision tree for feature importance on a classification problem\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define the model\n",
    "model = DecisionTreeClassifier()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print(\"Feature: %s, Score: %.5f\" % (X_train.columns[i], v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77ce16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame()\n",
    "df_imp[\"features\"] = X_train.columns\n",
    "df_imp[\"importance\"] = importance\n",
    "df_imp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33040b3e",
   "metadata": {},
   "source": [
    "#  Random Forest Classification Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086dd4b4",
   "metadata": {},
   "source": [
    "the importance of features calculated using the variance measure in Random Forest may not be the same as the actual predictive power of the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551d69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest for feature importance on a classification problem\n",
    "\n",
    "# define the model\n",
    "model = RandomForestClassifier()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print(\"Feature: %s, Score: %.5f\" % (X_train.columns[i], v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame()\n",
    "df_imp[\"features\"] = X_train.columns\n",
    "df_imp[\"importance\"] = importance\n",
    "df_imp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d45abb6",
   "metadata": {},
   "source": [
    "# xgboost feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe339d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check xgboost version\n",
    "print(xgboost.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d765bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost for feature importance on a classification problem\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# define dataset\n",
    "# X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# define the model\n",
    "model = XGBClassifier()\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i, v in enumerate(importance):\n",
    "    print(\"Feature: %s, Score: %.5f\" % (X_train.columns[i], v))\n",
    "# plot feature importance\n",
    "pyplot.bar([x for x in range(len(importance))], importance)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c457e07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imp = pd.DataFrame()\n",
    "df_imp[\"features\"] = X_train.columns\n",
    "df_imp[\"importance\"] = importance\n",
    "df_imp.sort_values(by=\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ee96a",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cf54d5",
   "metadata": {},
   "source": [
    "\n",
    "Logistic Regression is a Generalized Linear Model (GLM) such that:\n",
    "\n",
    "\n",
    "$$ P(C_{1}|\\textbf{x}) = \\frac{1}{1 - e^{\\textbf{w}^{T}\\phi(\\textbf{x})}}$$\n",
    "\n",
    "We tried to improve results obtained trought Naive Bayes approach using this slightly more sophisticated generative method trusting in an improvement. Being that the logistic regression model can be considered as the equivalent, for binary classification, of linear regression for the regression case it is still a simple method. \n",
    "Anyeway it is not only a classification model, but also gives back  probabilities. This is a big advantage over models that can only provide the final classification beacuse it is more informative.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37286f7",
   "metadata": {},
   "source": [
    "We decided to train the model with imputed and standardized data, in particular we decided to impute the model by replacing the values marked as -999,000 with the most frequent value relative to the particular feature. Comparing the results found on the internet relating to this type of classifiers it proved to be the method that guarantees the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0de9b0",
   "metadata": {},
   "source": [
    "Split the data for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fe2791",
   "metadata": {},
   "source": [
    "Using sklearn.linear_model.LogisticRegression funtion we maneged to create and fit the model.\n",
    "The fit consist in maximizing log-likehood function dependent on d + 1 parameters $\\textbf{w}=(w_{0},...,w_{d})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1aa5254",
   "metadata": {},
   "source": [
    "Parameters $\\textbf{w}=(w_{1},...,w_{d})$ are stored in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbe0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted: \", logreg.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27dfbb1",
   "metadata": {},
   "source": [
    "While intercept value $w_{0}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933b8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted: \", logreg.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf3b99",
   "metadata": {},
   "source": [
    "Once the model is optimized, it's possible to use it to evaluete test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99afd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = logreg.predict(X_val)\n",
    "prob_predict_val = logreg.predict_proba(X_val)\n",
    "print(\n",
    "    \"Accuracy of Logistic Regression classifier on validation set: {:.3f}\".format(\n",
    "        cross_val_score(logreg, X_val, y_val, cv=5, scoring=\"accuracy\").mean()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1109668",
   "metadata": {},
   "source": [
    "The function assign to singal or backgroung class the element with predicted probabiility pending respectively towards one or zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bda777",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted: \", y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c919d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicted: \", prob_predict_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f068af",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_val, y_val_pred)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb02723",
   "metadata": {},
   "source": [
    "It's interesting interpolate the AUC-ROC curve to visualize the performance of a classifier method. It is a performance measurement for classification problems at various thresholds settings. ROC is a probability curve and AUC represents degree or measure of separability. It tells how much model is capable of distinguishing between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76c5389",
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:, 1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=\"Logistic Regression (area = %0.2f)\" % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1], \"r--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver operating characteristic\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"Log_ROC\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "294px",
    "width": "328px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.264px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
